"""
LangGraph node definitions for conversation workflow.
Each node represents a step in the conversation processing pipeline.
"""

from typing import Dict, Any
from datetime import datetime
import json

from app.graph.state import ConversationState, ExtractedRequirements
from app.core.vector_store import get_vector_store
from app.core.llm import get_llm_service
from app.core.embeddings import get_embedding_service
from app.core.logging_config import get_logger
from app.services.backend_api import get_backend_api_service

logger = get_logger(__name__)


def receive_message(state: ConversationState) -> ConversationState:
    """Entry point - receives and preprocesses the user message.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with timestamp.
    """
    logger.debug(f"Node [receive_message]: Processing message for {state['phone_number']}")
    state["timestamp"] = datetime.now().isoformat()
    return state


def load_session_state(state: ConversationState) -> ConversationState:
    """Load persistent session state from database.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with loaded session data.
    """
    vector_store = get_vector_store()
    session_data = vector_store.get_customer_session(state["phone_number"])
    
    if session_data:
        # Merge existing session state - core fields
        state["extracted_requirements"] = session_data["extracted_requirements"]
        state["is_complete"] = session_data["is_complete"]
        # Workflow state fields (confirmation flow)
        state["confirmed"] = session_data.get("confirmed", False)
        state["awaiting_confirmation"] = session_data.get("awaiting_confirmation", False)
        state["confirmation_attempt"] = session_data.get("confirmation_attempt", 0)
        logger.info(f"Node [load_session_state]: Loaded existing session for {state['phone_number']} (confirmed: {state['confirmed']})")
    else:
        logger.debug(f"Node [load_session_state]: No existing session for {state['phone_number']}")
    
    return state


def retrieve_context(state: ConversationState) -> ConversationState:
    """Retrieve relevant context from vector store.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with conversation history and retrieved context.
    """
    vector_store = get_vector_store()
    
    # Get conversation history
    history = vector_store.get_conversation_history(
        phone_number=state["phone_number"],
        limit=10
    )
    
    state["conversation_history"] = history
    
    # Search for similar past conversations
    similar_messages = vector_store.search_similar(
        query=state["user_message"],
        phone_number=state["phone_number"],
        limit=3
    )
    
    # Format retrieved context
    context = [
        f"[{msg_type}]: {msg_text}"
        for msg_type, msg_text, score in similar_messages
        if score > 0.5  # Only include relevant matches
    ]
    state["retrieved_context"] = context
    
    logger.debug(f"Node [retrieve_context]: Found {len(history)} history messages and {len(context)} context snippets")
    return state


def build_workflow_hint(state: ConversationState) -> str:
    """Build context hint based on current workflow state.
    
    This helps the LLM understand what phase the conversation is in,
    improving intent detection accuracy for contextual responses.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Arabic hint string describing the current workflow state.
    """
    hint = ""
    
    # Confirmation phase
    if state.get("awaiting_confirmation"):
        attempt = state.get("confirmation_attempt", 1)
        hint = f"""
ðŸ”” Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: Ø§Ù†Ø§ Ø³Ø£Ù„Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù† ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}).
Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙØ³ÙŠØ±:
- Ø±Ø³Ø§Ù„Ø© Ø²ÙŠ "ØªÙ…Ø§Ù…"/"Ø§Ù‡"/"Ù†Ø¹Ù…"/"ok"/"Ù…Ø§Ø´ÙŠ" = confirm
- Ø±Ø³Ø§Ù„Ø© Ø²ÙŠ "Ù„Ø§"/"ØºÙ„Ø·"/"Ø¹Ø¯Ù„"/"ØºÙŠØ±" = edit
- Ù„Ùˆ Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¬Ø¯ÙŠØ¯ = inquiry
"""
    # Name correction phase
    elif state.get("awaiting_name_correction"):
        pending = state.get("pending_correction", {})
        field = pending.get("field", "Ø§Ø³Ù…")
        hint = f"""
ðŸ”” Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: Ø§Ù†Ø§ Ø³Ø£Ù„Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù† ØªØµØ­ÙŠØ­ {field}.
Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙØ³ÙŠØ±:
- Ù„Ùˆ Ø±Ø¯ Ø¨Ø§Ø³Ù… Ø¬Ø¯ÙŠØ¯ (ÙƒÙ„Ù…Ø© Ø£Ùˆ ÙƒÙ„Ù…ØªÙŠÙ†) = correction
- Ù„Ùˆ Ø±Ø¯ "ØµØ­"/"Ø§Ù‡" = confirm
"""
    # Missing data phase
    elif state.get("missing_fields"):
        missing = state.get("missing_fields", [])[:2]
        hint = f"""
ðŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ø§Ù‚ØµØ© Ù†Ø­ØªØ§Ø¬Ù‡Ø§: {missing}
- Ù„Ùˆ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø°ÙƒØ± Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠ = new_search Ø£Ùˆ update_requirements
"""
    
    # Add known requirements summary
    reqs = state.get("extracted_requirements", {})
    known = [f"{k}={v}" for k, v in reqs.items() if v][:4]
    if known:
        hint += f"\nðŸ“‹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹: {', '.join(known)}"
    
    return hint


def refine_intent(raw_intent: str, state: ConversationState) -> str:
    """Apply rule-based refinements to LLM intent classification.
    
    This catches edge cases where the LLM might misclassify
    based on message text alone without understanding workflow context.
    
    Args:
        raw_intent: The intent returned by the LLM.
        state: Current conversation state.
        
    Returns:
        Refined intent string.
    """
    msg = state["user_message"].lower()
    
    # Confirmation phase rules (including closing phase)
    # We check if awaiting_confirmation OR (is_complete and not confirmed)
    in_confirmation_phase = state.get("awaiting_confirmation") or (state.get("is_complete") and not state.get("confirmed"))

    if in_confirmation_phase:
        confirm_words = ["ØªÙ…Ø§Ù…", "ok", "Ø§Ù‡", "Ù†Ø¹Ù…", "ØµØ­", "Ù…Ø§Ø´ÙŠ", "Ø§ÙƒÙŠØ¯", "Ù…ÙˆØ§ÙÙ‚", "ØªØ£ÙƒÙŠØ¯", "Ø§ÙˆÙƒ", "tmam", "aywa", "ðŸ‘", "Ù…Ø¸Ø¨ÙˆØ·", "ÙƒØ¯Ø©", "ÙƒØ¯Ù‡", "Ø§ÙˆÙƒÙŠ", "Ø­Ø§Ø¶Ø±"]
        # Cancel MUST be checked BEFORE reject (since "Ù…Ø´ Ø¹Ø§ÙŠØ²" contains "Ù…Ø´")
        cancel_words = ["Ø®Ù„Ø§Øµ", "Ù…Ø´ Ø¹Ø§ÙŠØ²", "Ø§Ù„ØºÙŠ", "Ø¥Ù„ØºØ§Ø¡", "Ø§Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯", "cancel"]
        reject_words = ["ØºÙ„Ø·", "Ø¹Ø¯Ù„", "ØºÙŠØ±", "Ù„Ø£", "Ù„Ø£Ù‡", "no"]  # Removed "Ù…Ø´" and "Ù„Ø§" to avoid false positives
        
        
        # Priority 1: Check cancel first (most specific)
        if any(w in msg for w in cancel_words):
            logger.debug(f"[refine_intent] Override: {raw_intent} -> cancel (matched cancel word)")
            return "cancel"

        # Check if message is DATA (name/phone) vs pure confirmation
        is_reject = any(w in msg for w in reject_words)
        if not is_reject:
            msg_words = state["user_message"].split()
            # Check if ANY word is a confirm word
            has_confirm_word = any(w.lower() in confirm_words for w in msg_words)
            
            # FIXED LOGIC: If message has confirm word AND is short (<=5 words), it's likely pure confirmation
            # Examples: "Ø§Ù‡ ØªÙ…Ø§Ù… ÙƒØ¯Ø© Ù…Ø¸Ø¨ÙˆØ·" (4 words), "ØªÙ…Ø§Ù…" (1 word), "ok yes" (2 words)
            if has_confirm_word and len(msg_words) <= 5:
                # Even if LLM said something else, this is confirmation
                if raw_intent not in ["inquiry", "new_search"]:
                    logger.debug(f"[refine_intent] Override: {raw_intent} -> confirm (short msg with confirm word)")
                    return "confirm"
            
            # If message is long (>5 words) AND has substantial non-confirm content, might be data
            elif len(msg_words) > 5:
                non_confirm_words = [w for w in msg_words if w.lower() not in confirm_words]
                if len(non_confirm_words) >= 3:  # Increased threshold to avoid false positives
                    logger.debug(f"[refine_intent] Override: {raw_intent} -> update_requirements (long msg with data)")
                    return "update_requirements"
        
        if raw_intent in ["follow_up", "unknown", "greeting"]:
            # Priority 2: Confirmation
            if any(w in msg for w in confirm_words):
                logger.debug(f"[refine_intent] Override: {raw_intent} -> confirm (matched confirmation word)")
                return "confirm"
    
    # Name correction phase rules
    if state.get("awaiting_name_correction"):
        # Priority 1: Check for confirmation of suggested name FIRST
        # Use exact match or space-separated to avoid substring issues (e.g. 'Ù…Ø¯ÙŠÙ†ØªÙŠ' contains 'Ø¯ÙŠ')
        confirm_phrases = ["ØµØ­", "Ø§Ù‡", "Ù†Ø¹Ù…", "Ø§ÙƒÙŠØ¯", "Ø¯Ù‡ ØµØ­", "Ø¯ÙŠ ØµØ­", "Ø§Ù‡ Ø¯Ù‡", "Ø§Ù‡ Ø¯ÙŠ", "Ø§ÙŠÙˆÙ‡"]
        msg_words = msg.split()
        if any(w in msg_words for w in confirm_phrases) or msg.strip() in confirm_phrases:
            logger.debug(f"[refine_intent] Override: {raw_intent} -> confirm (confirmed suggested name)")
            return "confirm"
        
        # Priority 2: Short message = likely a name correction
        if raw_intent == "unknown" and len(state["user_message"].split()) <= 3:
            logger.debug(f"[refine_intent] Override: unknown -> correction (short message during name correction)")
            return "correction"
    
    return raw_intent


def detect_intent(state: ConversationState) -> ConversationState:
    """Detect the intent of the user message using state-aware classification.
    
    This function combines:
    1. Workflow state hints injected into the LLM prompt
    2. Rule-based post-processing for edge cases
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with detected intent.
    """
    llm_service = get_llm_service()
    
    # Build state-aware context hint
    workflow_hint = build_workflow_hint(state)
    
    intent_prompt = f"""Ø­Ù„Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ­Ø¯Ø¯ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
    
Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {state["user_message"]}
{workflow_hint}
Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
{json.dumps(state.get("conversation_history", [])[-3:], ensure_ascii=False)}

Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØ§Ø­Ø©:
- new_search: ÙŠØ¨Ø­Ø« Ø¹Ù† ÙˆØ­Ø¯Ø© Ø¹Ù‚Ø§Ø±ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© (ÙˆÙŠØ°ÙƒØ± Ù…ÙˆØ§ØµÙØ§Øª Ø£Ùˆ ÙŠØ·Ù„Ø¨ Ø§Ù„Ø¨Ø¯Ø¡)
- update_requirements: ÙŠØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„ Ù…ØªØ·Ù„Ø¨Ø§ØªÙ‡ Ø§Ù„Ù…Ø³Ø¬Ù„Ø©
- inquiry: ÙŠØ³Ø£Ù„ Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Ù…Ø´Ø§Ø±ÙŠØ¹ØŒ Ø£Ø³Ø¹Ø§Ø±ØŒ Ù…Ù†Ø§Ø·Ù‚ØŒ Ù…Ù‚Ø§Ø±Ù†Ø©) - ðŸš¨ Ø£ÙˆÙ„ÙˆÙŠØ© Ù‚ØµÙˆÙ‰ Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø¹Ù† "Ù…Ø´Ø§Ø±ÙŠØ¹" Ø£Ùˆ "Ø£Ø³Ø¹Ø§Ø±"
- follow_up: Ù…ØªØ§Ø¨Ø¹Ø© Ù„Ø·Ù„Ø¨ Ø³Ø§Ø¨Ù‚ (Ø¨Ø¯ÙˆÙ† Ø·Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©)
- greeting: ØªØ­ÙŠØ© ÙÙ‚Ø·
- confirm: ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©
- edit: ÙŠØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ£ÙƒÙŠØ¯
- correction: ÙŠØµØ­Ø­ Ø§Ø³Ù… Ù…Ù†Ø·Ù‚Ø©/Ù…Ø´Ø±ÙˆØ¹/Ù†ÙˆØ¹ ÙˆØ­Ø¯Ø©
- cancel: ÙŠØ±ÙŠØ¯ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯
- unknown: ØºÙŠØ± ÙˆØ§Ø¶Ø­

Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:
1. Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† "Ù…Ø´Ø§Ø±ÙŠØ¹"ØŒ "Ø£Ø³Ø¹Ø§Ø±"ØŒ "ØªÙØ§ØµÙŠÙ„"ØŒ "Ù…Ù†Ø§Ø·Ù‚" -> Ø§Ù„Ù†ÙŠØ© Ù‡ÙŠ 'inquiry' ÙÙˆØ±Ø§Ù‹.
2. Ù„Ø§ ØªØ®ØªØ± 'follow_up' Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Data Fetching needed).
3. Ø£Ø¬Ø¨ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ù†ÙŠØ© ÙÙ‚Ø· (ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©)."""

    response = llm_service.generate_response(
        user_message=intent_prompt,
        system_prompt="Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù†ÙˆØ§ÙŠØ§. Ø£Ø¬Ø¨ Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·."
    )
    
    # Parse intent from response
    intent_map = {
        "new_search": "new_search",
        "update_requirements": "update_requirements",
        "inquiry": "inquiry",
        "follow_up": "follow_up",
        "greeting": "greeting",
        "confirm": "confirm",
        "edit": "edit",
        "correction": "correction",
        "cancel": "cancel",
    }
    
    raw_intent = response.strip().lower()
    detected = intent_map.get(raw_intent, "unknown")
    
    # Apply rule-based refinements
    final_intent = refine_intent(detected, state)
    state["intent"] = final_intent
    
    logger.debug(f"Node [detect_intent]: Workflow hint used:\n{workflow_hint}")
    logger.debug(f"Node [detect_intent]: Raw LLM Response: {response}")
    logger.info(f"Node [detect_intent]: Raw: {detected} -> Final: {final_intent}")
    return state


def extract_requirements(state: ConversationState) -> ConversationState:
    """Extract customer requirements from message using LLM.
    NOW WITH DB-BASED TRANSLATION: Arabic â†’ English
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with extracted requirements in ENGLISH.
    """
    from app.services.name_matcher import get_name_matcher_service
    from app.services.backend_api import get_backend_api_service
    
    llm_service = get_llm_service()
    matcher = get_name_matcher_service()
    backend_api = get_backend_api_service()
    
    # FETCH DB VALUES for translation mapping
    try:
        areas = backend_api.get_areas()
        projects = backend_api.get_projects()
        unit_types = backend_api.get_unit_types()
        
        # Build translation maps
        area_map = "\n".join([f"- Arabic: '{a.get('name_ar', a['name'])}' â†’ English: '{a['name']}' (ID: {a['area_id']})" 
                              for a in areas if a.get('name') and a.get('area_id')])  # Check area_id exists
        project_map = "\n".join([f"- '{p['name']}' (ID: {p['project_id']}, Area: {p.get('area', {}).get('name', 'N/A')})" 
                                 for p in projects[:20] if p.get('name') and p.get('project_id')])  # Limit to avoid token overflow
        unit_type_map = "\n".join([f"- Arabic: 'Ø´Ù‚Ø©' â†’ 'Apartment', 'ÙÙŠÙ„Ø§' â†’ 'Villa', 'Ø¯ÙˆØ¨Ù„ÙƒØ³' â†’ 'Duplex', 'Ø§Ø³ØªÙˆØ¯ÙŠÙˆ' â†’ 'Studio'"])
        
    except Exception as e:
        logger.warning(f"Failed to fetch DB values for extraction: {e}")
        area_map = "- North Coast, New Capital, Tagamoo, Madinty, Sharm El Sheikh"
        project_map = "- Hawabay, Crystal Resort, etc."
        unit_type_map = "- Apartment, Villa, Duplex, Studio"
    
    extraction_prompt = f"""Ø§Ø³ØªØ®Ø±Ø¬ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠØ© Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØªØ±Ø¬Ù…Ù‡Ø§ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.

Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {state["user_message"]}

Ø³ÙŠØ§Ù‚ Ø³Ø§Ø¨Ù‚:
{json.dumps(state.get("retrieved_context", []), ensure_ascii=False)}

**Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø©:**
{area_map}

**Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…ØªØ§Ø­Ø© (Ø¹ÙŠÙ†Ø©):**
{project_map}

**Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙˆØ­Ø¯Ø§Øª:**
{unit_type_map}

Ø£Ø±Ø¬Ø¹ JSON Ø¨Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø¶Ø¹ null Ù„Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©):
{{
    "customer_name": "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© (Ù…Ø«Ù„ 'Ù…Ø­Ù…Ø¯ Ø§Ø­Ù…Ø¯'). null Ø¥Ø°Ø§ Ù„Ù… ÙŠØ°ÙƒØ±.",
    "customer_phone": "Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (Ù…Ø«Ù„ '010xxxx'). null Ø¥Ø°Ø§ Ù„Ù… ÙŠØ°ÙƒØ±.",
    "customer_email": "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (Ù…Ø«Ù„ 'example@mail.com'). null Ø¥Ø°Ø§ Ù„Ù… ÙŠØ°ÙƒØ±.",
    "area": "Ø§Ø³Ù… Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ø§Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¹Ù„Ø§Ù‡ Ù„Ù„ØªØ±Ø¬Ù…Ø©)",
    "area_id": Ø±Ù‚Ù… Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª,
    "project": "Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
    "project_id": Ø±Ù‚Ù… Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª,
    "unit_type": "Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Apartment/Villa/Duplex/Studio)",
    "budget_min": Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© (Ø±Ù‚Ù…),
    "budget_max": Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© (Ø±Ù‚Ù…),
    "size_min": Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…Ø³Ø§Ø­Ø© (Ø±Ù‚Ù…),
    "size_max": Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø³Ø§Ø­Ø© (Ø±Ù‚Ù…),
    "bedrooms": Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù (Ø±Ù‚Ù…),
    "bathrooms": Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù…Ø§Ù…Ø§Øª (Ø±Ù‚Ù…),
    "floor_preference": "ground_floor / high_floor / any",
    "needs_garden": true/false,
    "needs_roof": true/false,
    "additional_notes": "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"
}}

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
1. **CRITICAL**: Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©/Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù…ÙŠ!
   - "Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ ÙÙŠ Ø§Ù„Ø³Ø§Ø­Ù„ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠ" â†’ area: "North Coast", area_id: 6
   - "What projects in North Coast" â†’ area: "North Coast", area_id: 6
   - "Ø´Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ¬Ù…Ø¹" â†’ area: "Tagamoo", unit_type: "Apartment"
2. **ØªØ±Ø¬Ù… Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©**: Ø§Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¹Ù„Ø§Ù‡ Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
3. **Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª (IDs)**: Ø§Ø¨Ø­Ø« Ø¹Ù† area_id Ùˆ project_id Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
4. Floor: "Ø¯ÙˆØ± Ø£Ø±Ø¶ÙŠ"/"ground floor" â†’ "ground_floor" | "Ø¯ÙˆØ± Ø¹Ø§Ù„ÙŠ"/"high floor" â†’ "high_floor"
5. Garden: "Ø­Ø¯ÙŠÙ‚Ø©"/"garden" â†’ needs_garden=true
6. Roof: "Ø±ÙˆÙ"/"roof"/"Ø³Ø·Ø­" â†’ needs_roof=true

Ø£Ø±Ø¬Ø¹ JSON ÙÙ‚Ø·:"""

    response = llm_service.generate_response(
        user_message=extraction_prompt,
        system_prompt="Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù‚Ø§Ø±ÙŠØ©. Ø£Ø±Ø¬Ø¹ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø· Ù…Ø¹ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."
    )
    
    # Parse JSON response
    try:
        # Clean the response to get pure JSON
        json_str = response.strip()
        if json_str.startswith("```"):
            json_str = json_str.split("```")[1]
            if json_str.startswith("json"):
                json_str = json_str[4:]
        
        new_requirements = json.loads(json_str)
        
        # MERGE with existing requirements
        existing = state.get("extracted_requirements", {})
        merged = {**existing}
        
        # PROACTIVE FUZZY MATCHING: Match area/project against DB and ask for confirmation
        pending_confirmation_needed = False
        confirmation_messages = []
        
        for key, value in new_requirements.items():
            if value is not None and value != "null":
                if key in ["customer_name", "customer_email"]:
                    state[key] = value
                elif key == "customer_phone":
                    pass  # We have phone from webhook
                else:
                    # CRITICAL: Fuzzy match area/project immediately
                    if key == "area" and value:
                        match_result = matcher.match_area(value)
                        if match_result.matched:
                            # Got exact match â†’ use English name
                            merged["area"] = match_result.value
                            merged["area_id"] = match_result.id
                            # Ask user to confirm if input was Arabic
                            if value != match_result.value:  # Different = was Arabic
                                confirmation_messages.append(f"Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: **{match_result.value}**")
                                pending_confirmation_needed = True
                        elif match_result.alternatives:
                            # Ambiguous â†’ ask user to choose
                            state["area_alternatives"] = match_result.alternatives
                            state["area_original"] = value
                            pending_confirmation_needed = True
                            confirmation_messages.append(f"Ø§Ù„Ù…Ù†Ø·Ù‚Ø© '{value}' - ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ¶ÙŠØ­")
                        else:
                            # No match â†’ keep as-is for now
                            merged["area"] = value
                    
                    elif key == "project" and value:
                        area_id = merged.get("area_id")  # Use area_id if available
                        match_result = matcher.match_project(value, area_id=area_id)
                        if match_result.matched:
                            merged["project"] = match_result.value
                            merged["project_id"] = match_result.id
                            if value != match_result.value:
                                confirmation_messages.append(f"Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: **{match_result.value}**")
                                pending_confirmation_needed = True
                        elif match_result.alternatives:
                            state["project_alternatives"] = match_result.alternatives
                            state["project_original"] = value
                            pending_confirmation_needed = True
                            confirmation_messages.append(f"Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ '{value}' - ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ¶ÙŠØ­")
                        else:
                            merged["project"] = value
                    
                    else:
                        # Other fields â†’ merge directly
                        merged[key] = value
        
        state["extracted_requirements"] = merged
        
        # If we need confirmation, generate a confirmation message
        if pending_confirmation_needed and confirmation_messages:
            confirmation_text = "\n".join(confirmation_messages)
            state["awaiting_name_confirmation"] = True
            state["clarification_question"] = f"""ÙÙ‡Ù…Øª Ù…Ù†Ùƒ:\n{confirmation_text}\n\n**Ø§Ù†Øª Ù‚ØµØ¯Ùƒ ÙƒØ¯Ù‡ ØµØ­ØŸ** Ø§ÙƒØªØ¨ 'Ù†Ø¹Ù…' Ù„Ù„ØªØ£ÙƒÙŠØ¯ Ø£Ùˆ ØµØ­Ø­ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©."""
        
        
        # FIX: Infinite Loop Break - Auto-confirm if contact info provided during confirmation OR closing phase
        # We check if awaiting_confirmation OR (is_complete and not confirmed) - meaning we are in "booking" phase
        in_confirmation_phase = state.get("awaiting_confirmation") or (state.get("is_complete") and not state.get("confirmed"))
        
        if in_confirmation_phase:
            # Check if name or phone was JUST extracted
            new_name = new_requirements.get("customer_name")
            new_phone = new_requirements.get("customer_phone")
            
            # If we were missing them, and now we have them -> Auto Confirm
            missing_before = state.get("missing_fields", [])
            has_new_contact = (new_name and "customer_name" in missing_before) or \
                              (new_phone and "customer_phone" in missing_before) or \
                              (new_name and new_phone)
                              
            if has_new_contact:
                state["confirmed"] = True
                logger.info(f"Node [extract_requirements]: Auto-confirming request - User provided contact info: {new_name}, {new_phone}")

        logger.info(f"Node [extract_requirements]: Merged requirements - {len(merged)} fields, Confirmation needed: {pending_confirmation_needed}")
    except json.JSONDecodeError:
        logger.error("Node [extract_requirements]: Failed to parse LLM response as JSON")
        if "extracted_requirements" not in state:
            state["extracted_requirements"] = {}
        state["error"] = "Failed to parse requirements"
    
    return state


def check_missing_data(state: ConversationState) -> ConversationState:
    """Check for missing required data.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with missing fields list.
    """
    requirements = state.get("extracted_requirements", {})
    
    missing = []
    
    # Relaxed validation: Area + (Budget OR Size OR Type) is enough to start
    # Bedrooms and detailed size are optional "soft" requirements
    
    # Check Area
    if not requirements.get("area"):
        missing.append("area")

    # Check at least one other constraint to narrow down
    has_other_constraint = (
        requirements.get("unit_type") or 
        requirements.get("budget_max") or 
        requirements.get("size_min")
    )
    
    if not has_other_constraint:
         missing.append("requirements") # Generic missing tag
    
    # Optional suggestions logic remains...
            
    # HIERARCHY LOGIC:
    # If we have Area but NO Project, we should suggest projects (but it's not a blocking "missing field" for the request object itself,
    # unless we want to force project selection. Let's make it a suggestion step).
    # We'll treat "project" as a soft-requirement: if missing, we ask "Do you have a specific project?"
    # But if the user says "No" or ignores it, we proceed. to avoid blocking.
    # actually, user wants "Available projects should be listed".
    
    # HIERARCHY LOGIC:
    # If we have Area but NO Project, we check if there ARE projects to serve suggestions.
    if requirements.get("area") and not requirements.get("project") and not state.get("project_suggested"):
        from app.services.backend_api import get_backend_api_service
        backend_api = get_backend_api_service()
        projects = backend_api.get_projects(requirements.get("area"))
        
        if projects:
            state["should_suggest_projects"] = True
            logger.info(f"Node [check_missing_data]: Found {len(projects)} projects for {requirements.get('area')}, suggesting...")
        else:
            state["should_suggest_projects"] = False
            logger.debug(f"Node [check_missing_data]: No projects found for {requirements.get('area')}, skipping suggestion.")
    else:
        state["should_suggest_projects"] = False
    
    state["missing_fields"] = missing
    
    # If suggesting projects, we are NOT complete (we want to ask)
    if state.get("should_suggest_projects"):
        state["is_complete"] = False
        state["should_ask_clarification"] = True
    else:
        state["is_complete"] = len(missing) == 0
        state["should_ask_clarification"] = len(missing) > 0
    
    logger.info(f"Node [check_missing_data]: Complete: {state['is_complete']}, Missing: {missing}, Suggest Project: {state.get('should_suggest_projects')}")
    return state


def generate_clarification(state: ConversationState) -> ConversationState:
    """Generate a clarification question for missing data.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with clarification question.
    """
    if not state.get("should_ask_clarification"):
        return state
    
    
    missing = state.get("missing_fields", [])
    logger.info(f"Node [generate_clarification]: Entry - Suggest Project: {state.get('should_suggest_projects')}, Missing: {missing}")
    
    # Prioritize Project Suggestion
    if state.get("should_suggest_projects"):
        area_name = state.get("extracted_requirements", {}).get("area")
        from app.services.backend_api import get_backend_api_service
        backend_api = get_backend_api_service()
        projects = backend_api.get_projects(area_name)
        
        logger.info(f"Node [generate_clarification]: Suggesting for area '{area_name}' - Found {len(projects) if projects else 0} projects")
        
        if projects:
            project_list = "\n".join([f"â€¢ {p['name']}" for p in projects[:5]])
            state["clarification_question"] = f"Ù…Ù…ØªØ§Ø²! ÙÙŠ {area_name} Ø¹Ù†Ø¯Ù†Ø§ Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ù…ÙŠØ²Ø©:\n{project_list}\n\nØªØ­Ø¨ ØªØ­Ø¯Ø¯ Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¹ÙŠÙ† ÙˆÙ„Ø§ Ù†Ø¯ÙˆØ± ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© ÙƒÙ„Ù‡Ø§ØŸ"
            state["project_suggested"] = True # Mark as asked so we don't loop
            return state
        else:
            logger.warning(f"Node [generate_clarification]: 'should_suggest_projects' was True but no projects found for '{area_name}'.")
    
    # Field to Arabic mapping
    field_names = {
        "area": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©",
        "unit_type": "Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø©",
        "budget_max": "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©",
        "size_min": "Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù…ØªØ± Ù…Ø±Ø¨Ø¹)",
        "bedrooms": "Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù",
        "bathrooms": "Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù…Ø§Ù…Ø§Øª"
    }
    
    # Ask about the first missing field
    if missing:
        first_missing = missing[0]
        field_name = field_names.get(first_missing, first_missing)
        
        # Proactive area suggestion
        if first_missing == "area":
            from app.services.backend_api import get_backend_api_service
            backend_api = get_backend_api_service()
            areas = backend_api.get_areas()
            state["available_areas"] = areas
            area_list = "\n".join([f"â€¢ {a['name']}" for a in areas])
            state["clarification_question"] = f"Ù…Ù…ÙƒÙ† ØªØ­Ø¯Ø¯ Ù„ÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù„ÙŠ Ø¨ØªØ¯ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ØŸ\n\nØ§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹:\n{area_list}"
        
        elif first_missing == "unit_type":
            # Check if we have a project selected to filter types
            project_name = state.get("extracted_requirements", {}).get("project")
            
            # Default types
            unit_types = [
                {"name": "Ø´Ù‚Ø©", "id": "apartment"},
                {"name": "ÙÙŠÙ„Ø§", "id": "villa"},
                {"name": "ØªØ§ÙˆÙ† Ù‡Ø§ÙˆØ³", "id": "townhouse"},
                {"name": "Ø¯ÙˆØ¨Ù„ÙƒØ³", "id": "duplex"},
            ]
            
            msg_intro = "Ø§ÙŠÙ‡ Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù„ÙŠ Ø¨ØªØ¯ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ØŸ"
            
            if project_name:
                 msg_intro = f"ÙÙŠ {project_name}ØŒ Ø§ÙŠÙ‡ Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙŠÙƒØŸ"
            
            state["available_areas"] = unit_types  # Reusing available_areas field for buttons
            unit_list = "\n".join([f"â€¢ {u['name']}" for u in unit_types])
            state["clarification_question"] = f"{msg_intro}\n\nØ§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©:\n{unit_list}"
        
        elif first_missing == "size_min":
            state["clarification_question"] = "Ù…Ù…ÙƒÙ† ØªØ­Ø¯Ø¯ Ù„ÙŠ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ© Ø§Ù„Ù„ÙŠ Ù…Ø­ØªØ§Ø¬Ù‡Ø§ (Ø¨Ø§Ù„Ù…ØªØ± Ø§Ù„Ù…Ø±Ø¨Ø¹)ØŸ Ù‡Ø°Ø§ Ø§Ù„ØªÙØµÙŠÙ„ Ù…Ù‡Ù… Ø¹Ø´Ø§Ù† Ù†Ù„Ø§Ù‚ÙŠÙ„Ùƒ Ø§Ù„Ø£Ù†Ø³Ø¨."
            
        else:
            state["clarification_question"] = f"Ù…Ù…ÙƒÙ† ØªØ­Ø¯Ø¯ Ù„ÙŠ {field_name} Ø§Ù„Ù„ÙŠ Ø¨ØªØ¯ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ØŸ"
            
        logger.info(f"Node [generate_clarification]: Prepared question for: {first_missing}")
    
    return state


def requirement_confirmation(state: ConversationState) -> ConversationState:
    """Summarize requirements and ask for final confirmation.
    
    Features:
    - Varied messages based on confirmation attempt (fatigue handling)
    - Support for edit flow
    - Mandatory confirmation before request creation
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with confirmation question.
    """
    if not state.get("is_complete") or state.get("confirmed"):
        return state
    
    reqs = state.get("extracted_requirements", {})
    
    # Check if user intends to confirm (or provided contact info which implies confirmation)
    if state.get("intent") == "confirm" or (state.get("customer_name") and state.get("awaiting_confirmation")):
        
        # FINAL CHECK: Do we have contact info?
        if not state.get("customer_name"):
            state["response"] = """Ù…Ù…ØªØ§Ø²! Ø¹Ø´Ø§Ù† Ø£Ù‚Ø¯Ø± Ø£ÙƒÙ…Ù„ Ø§Ù„Ø­Ø¬Ø² ÙˆØ£Ø­ÙˆÙ„ Ø·Ù„Ø¨Ùƒ Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŒ Ù…Ø­ØªØ§Ø¬ Ù…Ù†Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©:

*   Ø§Ù„Ø§Ø³Ù… Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
*   Ø±Ù‚Ù… ØªÙ„ÙŠÙÙˆÙ† Ù„Ù„ØªÙˆØ§ØµÙ„ (Ù„Ùˆ ØºÙŠØ± Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ)

Ø§ÙƒØªØ¨Ù‡Ù… ÙÙŠ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆÙ‡ÙƒÙ…Ù„Ùƒ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ ÙÙˆØ±Ø§Ù‹. ðŸ‘‡"""
            state["awaiting_confirmation"] = True  # Still waiting, but now for contact info
            return state
            
        # We have contact info -> PROCEED
        state["confirmed"] = True
        state["awaiting_confirmation"] = False
        logger.info(f"Node [requirement_confirmation]: User confirmed requirements. Name: {state.get('customer_name')}")
        return state
    
    # Check if user wants to edit
    if state.get("intent") == "edit":
        state["awaiting_confirmation"] = False
        logger.info("Node [requirement_confirmation]: User wants to edit")
        return state
    
    # Get confirmation attempt count
    attempt = state.get("confirmation_attempt", 0)
    
    # Field labels for summary
    labels = {
        "area": "ðŸ“ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©",
        "project": "ðŸ—ï¸ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        "unit_type": "ðŸ  Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø©",
        "budget_max": "ðŸ’° Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©",
        "bedrooms": "ðŸ›ï¸ Ø§Ù„ØºØ±Ù",
        "bathrooms": "ðŸš¿ Ø§Ù„Ø­Ù…Ø§Ù…Ø§Øª",
        "size_max": "ðŸ“ Ø§Ù„Ù…Ø³Ø§Ø­Ø© (Ù…2)"
    }
    
    summary_parts = []
    for key, label in labels.items():
        val = reqs.get(key)
        if val:
            summary_parts.append(f"â€¢ {label}: {val}")
    
    summary = "\n".join(summary_parts)
    
    # Varied intro based on attempt (fatigue handling) or if no units found
    matched_units = state.get("matched_units", [])
    
    if not matched_units:
        intro = "Ù„Ù„Ø£Ø³Ù Ù…Ù„Ø§Ù‚ÙŠØªØ´ ÙˆØ­Ø¯Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ø§Ù„Ø¸Ø¨Ø· ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø§Ù„ÙŠØ§Ù‹ ðŸ˜”\n\nÙ„ÙƒÙ† ÙˆÙ„Ø§ ÙŠÙ‡Ù…Ùƒ! Ù…Ù…ÙƒÙ† Ø£Ø³Ø¬Ù„ Ø·Ù„Ø¨Ùƒ ÙÙˆØ±Ø§Ù‹ ÙˆÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ù‡ÙŠØ¯ÙˆØ± Ù„Ùƒ Ù…Ø®ØµÙˆØµ ÙˆÙŠØªÙˆØ§ØµÙ„ Ù…Ø¹Ø§Ùƒ.\n\nØ¯ÙŠ ØªÙØ§ØµÙŠÙ„ Ø·Ù„Ø¨Ùƒ:\n\n"
        closing = "\n\n**ØªØ­Ø¨ Ø£Ø³Ø¬Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¯ÙŠØŸ**"
    elif attempt == 0:
        intro = "Ø®Ù„ÙŠÙ†ÙŠ Ø£ØªØ£ÙƒØ¯ Ù…Ù† Ø·Ù„Ø¨Ùƒ:\n\n"
        closing = "\n\n**ÙƒØ¯Ù‡ ØªÙ…Ø§Ù…ØŸ** ÙˆÙ„Ø§ ØªØ­Ø¨ ØªØ¹Ø¯Ù„ Ø­Ø§Ø¬Ø©ØŸ"
    elif attempt == 1:
        intro = "ØªÙ…Ø§Ù…ØŒ Ø®Ù„ÙŠÙ†Ø§ Ù†Ø±Ø§Ø¬Ø¹Ù‡Ø§ Ù…Ø±Ø© Ø£Ø®ÙŠØ±Ø© Ø¨Ø³ ðŸ‘Œ\n\n"
        closing = "\n\n**ÙƒØ¯Ù‡ ØµØ­ØŸ**"
    else:
        intro = "Ø¢Ø®Ø± Ù…Ø±Ø§Ø¬Ø¹Ø©:\n\n"
        closing = "\n\n**Ù†Ø£ÙƒØ¯ ÙˆÙ†Ø¨Ø¯Ø£ØŸ**"
    
    state["response"] = f"{intro}{summary}{closing}"
    state["awaiting_confirmation"] = True
    state["confirmation_attempt"] = attempt + 1
    
    # Provide buttons
    state["confirmation_buttons"] = [
        {"name": "ØªØ£ÙƒÙŠØ¯ âœ…", "id": "confirm"},
        {"name": "ØªØ¹Ø¯ÙŠÙ„ ðŸ“", "id": "edit"}
    ]
    
    logger.info(f"Node [requirement_confirmation]: Attempt {attempt + 1} - asking for confirmation")
    return state


def generate_response(state: ConversationState) -> ConversationState:
    """Generate the final response using LLM.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with generated response.
    """
    # If a response is already prepared (e.g., by confirmation or inquiry node), keep it
    if state.get("response") and (state.get("intent") == "confirm" or not state.get("is_complete") and state.get("confirmed") is False):
        if state.get("intent") == "confirm" and state.get("confirmed"):
             # After confirmation, we might want a success message
             state["response"] = "ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨Ùƒ Ù„Ù„ÙˆØ³Ø·Ø§Ø¡. Ù‡Ù‚ÙˆÙ… Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØ­Ø¯Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù…ÙˆØ§ØµÙØ§ØªÙƒ Ø§Ù„Ø¢Ù†."
        else:
             return state
    
    # If we're in confirmation flow (response already set by requirement_confirmation)
    if state.get("response") and state.get("is_complete") and not state.get("confirmed"):
        logger.info(f"Node [generate_response]: Source -> Confirmation Flow")
        return state

    llm_service = get_llm_service()
    
    # Build context from retrieved messages
    context = "\n".join(state.get("retrieved_context", []))
    
    # Build the response based on intent and state
    if state.get("intent") == "greeting":
        from app.services.backend_api import get_backend_api_service
        backend_api = get_backend_api_service()
        areas = backend_api.get_areas()
        area_list = "\n".join([f"â€¢ {a['name']}" for a in areas])
        
        state["response"] = f"""Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª.

Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø¥ÙŠØ¬Ø§Ø¯ ÙˆØ­Ø¯Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ø¯ÙŠÙ†Ø§:
{area_list}

Ø­Ø§Ø¨Ø¨ ØªØ¨Ø¯Ø£ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø£ÙŠ Ù…Ù†Ø·Ù‚Ø©ØŸ"""
        return state
    
    # Handle Inquiry Response
    if state.get("intent") == "inquiry":
        inquiry_results = state.get("inquiry_results", {})
        
        # Check if we need to capture a lead instead of answering
        if inquiry_results.get("type") == "lead_capture_needed":
            state["response"] = """Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù†Ø³Ø¨ ÙˆØ­Ø¯Ø© Ø¹Ù‚Ø§Ø±ÙŠØ© Ù„Ùƒ.
            
ÙˆØ¹Ø´Ø§Ù† Ø£Ù‚Ø¯Ø± Ø£Ø®Ø¯Ù…Ùƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ØŒ Ù…Ø­ØªØ§Ø¬ Ø£Ø¹Ø±Ù Ø´ÙˆÙŠØ© ØªÙØ§ØµÙŠÙ„:
1. Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù„ÙŠ Ø¨ØªÙØ¶Ù„Ù‡Ø§ØŸ
2. Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©ØŸ
3. Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø© (Ø´Ù‚Ø©ØŒ ÙÙŠÙ„Ø§ØŒ Ø¥Ù„Ø®)ØŸ

Ø¨Ù…Ø¬Ø±Ø¯ Ù…Ø§ ØªØ¯ÙŠÙ†ÙŠ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¯ÙŠØŒ Ù‡Ø³Ø¬Ù„ Ø·Ù„Ø¨Ùƒ ÙˆØ£Ø®Ù„ÙŠ Ø­Ø¯ Ù…Ù† Ø§Ù„ÙØ±ÙŠÙ‚ ÙŠØªÙˆØ§ØµÙ„ Ù…Ø¹Ø§Ùƒ ÙÙˆØ±Ø§Ù‹."""
            # Reset complete state to encourage requirement gathering if not already started
            state["is_complete"] = False
            return state

        # CRITICAL FIX: Reduce data sent to LLM to prevent token overflow
        # Only send essential fields, not full objects
        inquiry_type = inquiry_results.get("type")
        limited_results = {"type": inquiry_type}
        
        if inquiry_type == "projects" and inquiry_results.get("data"):
            # Only send project names and count, not full objects
            projects = inquiry_results["data"]
            limited_results["count"] = len(projects)
            limited_results["names"] = [p.get("name") for p in projects[:10]]  # Max 10 names
            limited_results["area"] = inquiry_results.get("area_filter")
        elif inquiry_type == "units_search" and inquiry_results.get("data"):
            # Only send unit count and basic info
            units = inquiry_results["data"]
            limited_results["count"] = len(units)
            limited_results["sample"] = [{
                "type": u.get("unitType"),
                "price": u.get("price"),
                "size": u.get("size"),
                "project": u.get("project", {}).get("name")
            } for u in units[:5]]  # Max 5 samples
        elif inquiry_type == "price_range":
            # Price range is already small
            limited_results["data"] = inquiry_results.get("data", {})
        elif inquiry_type == "ambiguous_entity":
            limited_results["entity_type"] = inquiry_results.get("entity_type")
            limited_results["original"] = inquiry_results.get("original")
            limited_results["alternatives"] = inquiry_results.get("alternatives", [])[:5]  # Max 5
        
        elif inquiry_type == "general_qa":
            # Allow general Q&A using RAG context
            limited_results["note"] = "General inquiry - use constraints from context"

        # CRITICAL FIX: Strict anti-hallucination prompt with LIMITED data
        if inquiry_type == "general_qa":
             # Relaxed prompt for general questions
             system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª Ø°ÙƒÙŠ. Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù….
             
             Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
             1. Ø£Ø¬Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ (Context) ÙÙ‚Ø·.
             2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù„Ø¯ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø¤ÙƒØ¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹".
             3. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ø§Ù‹.
             """
        else:
             # Strict data-driven prompt for specific search results
             system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª Ø°ÙƒÙŠ. Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù…ÙŠ.
    
             **Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© - ÙŠØ­Ø¸Ø± ØªÙ…Ø§Ù…Ø§Ù‹ Ù…Ø®Ø§Ù„ÙØªÙ‡Ø§:**
             1. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙ‚Ø·** Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø£Ø¯Ù†Ø§Ù‡
             2. **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹** Ø§Ø®ØªØ±Ø§Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø£Ùˆ Ø£Ø³Ø¹Ø§Ø± Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
             3. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙØ§Ø±ØºØ© Ø£Ùˆ nullØŒ Ù‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹"
             4. **Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ Ø§Ø³Ù… Ù…Ø´Ø±ÙˆØ¹ Ø£Ùˆ Ø³Ø¹Ø± Ù„ÙŠØ³ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¯Ù†Ø§Ù‡**
             
             Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« (Ù…Ø­Ø¯ÙˆØ¯Ø©): {json.dumps(limited_results, ensure_ascii=False)}
             
             **Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
             - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© "ambiguous_entity": Ø£Ø®Ø¨Ø± Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø£Ù†Ùƒ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø§Ø³Ù… Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙˆØ§Ø¹Ø±Ø¶ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ù…Ù† "alternatives"
             - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© "projects": Ø§Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ù† "names" ÙÙ‚Ø· ÙˆØ¹Ø¯Ø¯Ù‡Ø§ Ù…Ù† "count"
             - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª "data" ÙØ§Ø±ØºØ© Ø£Ùˆ null: Ù‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…ØªØ§Ø­Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
             - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª "units_search": Ø§Ø¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª ÙˆØ¹ÙŠÙ†Ø© Ù…Ù† "sample" Ù…Ø¹ Ø£Ø³Ø¹Ø§Ø±Ù‡Ø§ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙ‚Ø·
             - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª "price_range": Ø§Ø¹Ø±Ø¶ min/max/count Ù…Ù† "data"
             
             **ØªØ­Ø°ÙŠØ± Ø£Ø®ÙŠØ±**: Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø£Ø¹Ù„Ø§Ù‡ Ù‡ÙŠ Ø§Ø®ØªØ±Ø§Ø¹ Ù…Ø­Ø¸ÙˆØ±."""
        
        logger.info(f"Node [generate_response]: Source -> Inquiry Results (Anti-Hallucination Mode, Limited Data)")
        response = llm_service.generate_response(
            user_message=state["user_message"],
            context=context,
            conversation_history=state.get("conversation_history"),
            system_prompt=system_prompt
        )
        state["response"] = response
        return state
    
    if state.get("should_ask_clarification") and state.get("clarification_question"):
        # Combine acknowledgment with clarification
        llm_service = get_llm_service()
        logger.info(f"Node [generate_response]: Source -> Clarification Question")
        response = llm_service.generate_response(
            user_message=state["user_message"],
            context=context,
            conversation_history=state.get("conversation_history"),
            system_prompt=f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª. Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø£Ø±Ø³Ù„ Ø±Ø³Ø§Ù„Ø© ÙˆÙ…Ø­ØªØ§Ø¬ ØªÙˆØ¶ÙŠØ­.
            
Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {json.dumps(state.get("extracted_requirements", {}), ensure_ascii=False)}
Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {state["clarification_question"]}

Ø§Ø¹ØªØ±Ù Ø¨Ù…Ø§ ÙÙ‡Ù…ØªÙ‡ØŒ Ø«Ù… Ø§Ø³Ø£Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ. ÙƒÙ† Ù…ÙˆØ¬Ø²Ø§Ù‹ ÙˆÙˆØ¯ÙˆØ¯Ø§Ù‹."""
        )
        state["response"] = response
    else:
        # Check if we have unit search results
        matched_units = state.get("matched_units", [])
        request_id = state.get("request_id")
        
        if state.get("is_complete") and request_id:
            # Request successfully created - Confirm assignment to broker
            units_section = ""
            if matched_units:
                units_list = chr(10).join([f"â€¢ {u['unit_code']} - {u.get('price', 'Ø§Ù„Ø³Ø¹Ø± Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨')} Ø¬Ù†ÙŠØ©" for u in matched_units[:3]])
                units_section = f"\n\nØ§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹:\n{units_list}"
            
            state["response"] = f"""ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨Ùƒ Ø¨Ù†Ø¬Ø§Ø­! âœ…
Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨: #{request_id}

ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø·Ù„Ø¨Ùƒ Ù„Ø£Ø­Ø¯ Ù…Ø³ØªØ´Ø§Ø±ÙŠÙ†Ø§ Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙŠÙ† ÙÙŠ ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª. Ù‡ÙŠØªÙˆØ§ØµÙ„ Ù…Ø¹Ø§Ùƒ ÙÙŠ Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª Ø¹Ø´Ø§Ù† ÙŠØ¹Ø±Ø¶ Ø¹Ù„ÙŠÙƒ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¨Ø£Ø³Ø¹Ø§Ø±Ù‡Ø§ ÙˆØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø³Ø¯Ø§Ø¯.{units_section}

Ù‡Ù„ ØªØ­Ø¨ Ù†Ø¹Ù…Ù„ Ø¨Ø­Ø« ØªØ§Ù†ÙŠØŸ"""
            logger.info(f"Node [generate_response]: Source -> Request Created Success")
            return state
        
        elif state.get("is_complete") and state.get("area_not_found"):
            # Area not found scenario
             pass # Will fallthrough to LLM or handle explicitly
             
        # FALLBACK / GENERIC RESPONSE
        # Ensuring we pass matched units to context if available
        units_context = ""
        if matched_units:
            units_context = f"\nMatched Units Details:\n{json.dumps(matched_units, ensure_ascii=False)}"
        
        system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø©.
        
        ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:
        1. Ù„Ø§ ØªØ°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø£Ùˆ ÙˆØ­Ø¯Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© (Matched Units).
        2. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ ÙˆØ­Ø¯Ø§Øª ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ù‚Ù„ Ø£Ù†Ùƒ Ø³ØªÙ‚ÙˆÙ… Ø¨ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ø¨Ø­Ø«.
        3. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ø­ØªØ±ÙØ§Ù‹.
        
        {units_context}"""
        
        logger.info(f"Node [generate_response]: Source -> Generic Fallback")
        response = llm_service.generate_response(
            user_message=state["user_message"],
            context=context,
            conversation_history=state.get("conversation_history"),
            system_prompt=system_prompt
        )
        state["response"] = response
        return state

        # If search completed but not confirmed yet
        if matched_units:
             # Construct units string for LLM context
             units_str = json.dumps(matched_units[:5], ensure_ascii=False)
             
             system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª. ÙˆØ¬Ø¯Øª Ø¨Ø¹Ø¶ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ø¹Ù…ÙŠÙ„.
             
Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:
{units_str}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. Ù‚Ø¯Ù… Ø£ÙØ¶Ù„ 3 Ø®ÙŠØ§Ø±Ø§Øª Ù„Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨Ù‡.
2. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙ‚Ø· (Ø§Ù„Ø³Ø¹Ø±ØŒ Ø§Ù„Ù…Ø³Ø§Ø­Ø©ØŒ Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹) Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡.
3. Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø«Ù„ "Ø§Ø³Ù… Ø§Ù„ÙƒÙ…Ø¨Ø§ÙˆÙ†Ø¯" Ø£Ùˆ "Ø§Ù„Ø³Ø¹Ø±").
4. Ø§Ø³Ø£Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ±ÙŠØ¯ Ø­Ø¬Ø² Ø£ÙŠ Ù…Ù†Ù‡Ø§.
"""
             response = llm_service.generate_response(
                user_message=state["user_message"],
                context=context,
                conversation_history=state.get("conversation_history"),
                system_prompt=system_prompt
             )
             state["response"] = response
             return state
        
        elif state.get("available_areas"):
            # Area not found - suggest available areas to user
            area_not_found = state.get("area_not_found", "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
            available_areas = state.get("available_areas", [])
            
            # Format available areas list
            areas_list = "\n".join([f"â€¢ {area['name']}" for area in available_areas])
            
            state["response"] = f"""Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù†Ø·Ù‚Ø© ØªØ³Ù…Ù‰ "{area_not_found}" ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ù‡ÙŠ:
{areas_list}

Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ ÙˆØ³Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©."""
            
            # Mark as not complete so user can specify correct area
            state["is_complete"] = False
        
        elif state.get("is_complete") and not request_id and not state.get("available_areas"):
            # Complete but request creation failed (shouldn't happen often if areas check passed)
            state["response"] = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¨Ø³ÙŠØ· Ø£Ø«Ù†Ø§Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø·Ù„Ø¨ÙƒØŒ ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªÙ‚Ù„Ù‚. Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ø¨Ù„Ø§Øº Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙÙˆØ±Ø§Ù‹. Ù‡Ù„ ØªØ­Ø¨ Ø£Ù† ØªØªØ±Ùƒ Ù„ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø© Ø¥Ø¶Ø§ÙÙŠØ©ØŸ"
        
        else:
            # Generate regular response
            response = llm_service.generate_response(
                user_message=state["user_message"],
                context=context,
                conversation_history=state.get("conversation_history")
            )
            state["response"] = response
    
    return state


def format_units_for_display(units: list) -> str:
    """Format unit search results for display in Arabic.
    
    Args:
        units: List of unit dictionaries from backend.
        
    Returns:
        Formatted string with unit details.
    """
    if not units:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…ØªØ§Ø­Ø©"
    
    formatted = []
    for i, unit in enumerate(units[:5], 1):  # Top 5 units
        project_name = unit.get("project", {}).get("name", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
        area_name = unit.get("project", {}).get("area", {}).get("name", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
        unit_type = unit.get("unitType", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
        size = unit.get("size", 0)
        price = unit.get("price", 0)
        building = unit.get("building", "")
        floor = unit.get("floor", "")
        
        # Format price in millions if over 1M
        if price >= 1000000:
            price_str = f"{price / 1000000:.1f} Ù…Ù„ÙŠÙˆÙ† Ø¬Ù†ÙŠÙ‡"
        else:
            price_str = f"{price:,.0f} Ø¬Ù†ÙŠÙ‡"
        
        unit_details = f"""{i}. {unit_type} - {project_name}
   ðŸ“ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {area_name}
   ðŸ“ Ø§Ù„Ù…Ø³Ø§Ø­Ø©: {size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
   ðŸ’° Ø§Ù„Ø³Ø¹Ø±: {price_str}"""
        
        if building:
            unit_details += f"\n   ðŸ¢ Ø§Ù„Ù…Ø¨Ù†Ù‰: {building}"
        if floor:
            unit_details += f" - Ø§Ù„Ø¯ÙˆØ±: {floor}"
        
        formatted.append(unit_details)
    
    return "\n\n".join(formatted)


def persist_conversation(state: ConversationState) -> ConversationState:
    """Persist the conversation to vector store.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Same state (final node).
    """
    vector_store = get_vector_store()
    
    # Store user message
    vector_store.store_message(
        phone_number=state["phone_number"],
        message_type="user",
        message_text=state["user_message"],
        metadata={
            "intent": state.get("intent"),
            "requirements": state.get("extracted_requirements"),
            "timestamp": state.get("timestamp")
        }
    )
    
    # Store assistant response
    if state.get("response"):
        vector_store.store_message(
            phone_number=state["phone_number"],
            message_type="assistant",
            message_text=state["response"],
            metadata={
                "timestamp": state.get("timestamp")
            }
        )
    
    return state


def save_session_state(state: ConversationState) -> ConversationState:
    """Save current session state to database.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Same state.
    """
    vector_store = get_vector_store()
    vector_store.save_customer_session(
        phone_number=state["phone_number"],
        extracted_requirements=state.get("extracted_requirements", {}),
        last_intent=state.get("intent", "unknown"),
        is_complete=state.get("is_complete", False),
        confirmed=state.get("confirmed", False),
        awaiting_confirmation=state.get("awaiting_confirmation", False),
        confirmation_attempt=state.get("confirmation_attempt", 0)
    )
    logger.debug(f"Node [save_session_state]: Session saved for {state['phone_number']} (confirmed: {state.get('confirmed')})")
    return state


def search_units(state: ConversationState) -> ConversationState:
    """Search for matching units from backend.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with matched units.
    """
    if not state.get("is_complete"):
        logger.debug("Node [search_units]: Skipping - requirements not complete")
        return state
    
    backend_api = get_backend_api_service()
    reqs = state.get("extracted_requirements", {})
    
    try:
        units = backend_api.search_units(
            area_name=reqs.get("area"),
            project_name=reqs.get("project"),
            unit_type=reqs.get("unit_type"),
            budget_max=reqs.get("budget_max"),
            size_min=reqs.get("size_min"),
            bedrooms=reqs.get("bedrooms")
        )
        
        state["matched_units"] = units[:5]  # Top 5 results
        logger.info(f"Node [search_units]: Found {len(units)} matching units")
    except Exception as e:
        logger.error(f"Node [search_units]: Error - {e}")
        state["matched_units"] = []
    
    return state


def create_customer_request(state: ConversationState) -> ConversationState:
    """Create formal request in backend CRM.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with request_id.
    """
    if not state.get("is_complete") or not state.get("confirmed"):
        logger.debug("Node [create_request]: Skipping - requirements not complete or confirmed")
        return state
    
    backend_api = get_backend_api_service()
    reqs = state.get("extracted_requirements", {})
    
    try:
        # Get or create customer with updated contact info
        customer_data = {
            "name": reqs.get("customer_name") or state.get("customer_name"),
            "phone": reqs.get("customer_phone") or state["phone_number"],
            "email": reqs.get("customer_email")
        }
        
        customer_id = backend_api.get_or_create_customer(
            phone=state["phone_number"],
            name=customer_data["name"]
        )
        # Update customer info if new details provided
        if customer_data["name"] or customer_data["email"]:
            # Note: You might want a backend method to update customer details, 
            # or pass them to create_request to handle persistence.
            pass

        # Get area ID
        area_name = reqs.get("area")
        if area_name:
            area_id = backend_api.get_area_id_by_name(area_name)
            if area_id:
                # Create request
                request_id = backend_api.create_request(
                    customer_id=customer_id,
                    area_id=area_id,
                    requirements=reqs
                )
                state["request_id"] = request_id
                state["customer_id"] = customer_id
                state["confirmed"] = False  # Reset for future requests if needed
                logger.info(f"Node [create_request]: Created request {request_id} for customer {customer_id}")
                
                # Sync conversation history to persistent SQL storage
                try:
                    vector_store = get_vector_store()
                    # Fetch recent history (last 20 messages)
                    history = vector_store.get_conversation_history(state["phone_number"], limit=20)
                    
                    synced_count = 0
                    for msg in history:
                        # Map role to actor_type
                        # 'user' -> 'customer', 'assistant' -> 'ai'
                        if msg['role'] == 'user':
                            actor_type = 'customer'
                            actor_id_val = customer_id
                        else:
                            actor_type = 'ai'
                            actor_id_val = None
                            
                        success = backend_api.save_conversation(
                            request_id=request_id,
                            actor_type=actor_type,
                            message=msg['content'],
                            actor_id=actor_id_val
                        )
                        if success:
                            synced_count += 1
                            
                    logger.info(f"Node [create_request]: Synced {synced_count} messages to conversations table")
                    
                except Exception as e:
                    logger.error(f"Node [create_request]: Error syncing history - {e}")

            else:
                # Area not found - fetch all available areas to suggest
                logger.warning(f"Node [create_request]: Area '{area_name}' not found - fetching alternatives")
                all_areas = backend_api.get_areas()
                state["available_areas"] = all_areas
                state["area_not_found"] = area_name
                state["request_id"] = None  # Ensure request_id is None
                logger.info(f"Node [create_request]: Fetched {len(all_areas)} available areas for suggestion")
        else:
            logger.warning("Node [create_request]: No area specified in requirements")
    
    except Exception as e:
        logger.error(f"Node [create_request]: Error - {e}")
    
    return state


def classify_inquiry_logic(user_message: str, context_str: str = "") -> dict:
    """Classify user inquiry using a lightweight LLM router.
    
    Uses Cohere command-r7b-12-2024 for speed.
    """
    llm_service = get_llm_service()
    
    router_prompt = f"""You are a smart router for a Real Estate Chatbot. 
    Analyze the user's question and classify it into ONE of these categories:
    
    1. price_check: Question about price, cost, down payment, installments.
    2. availability_check: Question about what units are available, types (apartments/villas), or specific availability.
    3. project_comparison: Asking to compare 2+ projects or areas.
    4. location_info: Asking about a specific area, location, or where something is.
    5. general_qa: General questions about the company, real estate market, or generic "how are you".
    
    User Message: "{user_message}"
    Context: {context_str}
    
    Return JSON ONLY:
    {{
        "type": "category_name",
        "entities": {{
            "project": "extracted_project_name_or_null",
            "area": "extracted_area_name_or_null",
            "unit_type": "extracted_unit_type_or_null"
        }}
    }}
    """
    
    try:
        response = llm_service.generate_response(
            user_message=router_prompt,
            system_prompt="You are a JSON-only classification router. Output valid JSON."
        )
        
        # Parse JSON
        import re
        json_match = re.search(r"\{.*\}", response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        return {"type": "general_qa", "entities": {}}
        
    except Exception as e:
        logger.error(f"Router failed: {e}")
        return {"type": "general_qa", "entities": {}}


def handle_inquiry(state: ConversationState) -> ConversationState:
    """Handle general inquiry requests using Smart LLM Routing.
    
    Replaces keyword matching with semantic classification.
    """
    backend_api = get_backend_api_service()
    from app.services.name_matcher import get_name_matcher_service
    matcher = get_name_matcher_service()
    
    message = state["user_message"]
    reqs = state.get("extracted_requirements", {})
    
    # Context for extraction (e.g. if we know they are looking in New Capital)
    context_str = f"Current Focus: Area={reqs.get('area')}, Project={reqs.get('project')}"
    
    # 1. CLASSIFY
    classification = classify_inquiry_logic(message, context_str)
    inquiry_type = classification.get("type", "general_qa")
    entities = classification.get("entities", {})
    
    logger.info(f"Node [handle_inquiry]: Smart Router Classification -> {inquiry_type} | Entities: {entities}")
    state["inquiry_classification"] = classification
    
    results = {}
    
    try:
        # Merge extracted entities with state requirements if trusted
        target_project_name = entities.get("project") or reqs.get("project")
        target_area_name = entities.get("area") or reqs.get("area")
        target_unit = entities.get("unit_type") or reqs.get("unit_type") # This might need mapping too

        # Resolve IDs
        target_project_id = reqs.get("project_id")
        target_area_id = reqs.get("area_id")

        if target_project_name and not target_project_id:
             p_match = matcher.match_project(target_project_name)
             if p_match.matched:
                 target_project_id = p_match.id
                 target_project_name = p_match.value # Canonical name
        
        if target_area_name and not target_area_id:
             a_match = matcher.match_area(target_area_name)
             if a_match.matched:
                 target_area_id = a_match.id
                 target_area_name = a_match.value

        # Map Unit Type (Arabic -> English)
        if target_unit:
             # simple quick mapping or use the one from extract_requirements logic if reusable
             # For now, let's reuse the mapping logic if possible or duplicate simple version
             type_map = {
                'Ø´Ù‚Ø©': 'Apartment', 'Ø´Ù‚Ù‚': 'Apartment',
                'ÙÙŠÙ„Ø§': 'Villa', 'ÙÙ„Ù„': 'Villa',
                'ØªØ§ÙˆÙ†': 'Town House', 'ØªÙˆÙŠÙ†': 'Twin House',
                'Ø´Ø§Ù„ÙŠÙ‡': 'Chalet', 'Ø³ØªÙˆØ¯ÙŠÙˆ': 'Studio'
             }
             for k, v in type_map.items():
                 if k in target_unit:
                     target_unit = v
                     break

        # --- ROUTING LOGIC ---
        
        if inquiry_type == "price_check":
            price_data = backend_api.get_price_range(
                project_id=target_project_id,
                area_id=target_area_id,
                unit_type=target_unit
            )
            results["type"] = "price_range"
            results["data"] = price_data
            results["filters"] = {"project": target_project_name, "area": target_area_name, "unit_type": target_unit}
            
        elif inquiry_type == "project_comparison":
             results["type"] = "comparison_needed"
             results["message"] = "Specify projects to compare"
             
        elif inquiry_type == "availability_check":
             if target_project_id or target_area_id:
                 if target_project_id:
                     # Check specific project units
                     units = backend_api.search_units(
                         project_id=target_project_id, 
                         unit_type=target_unit,
                         limit=5
                     )
                     results["type"] = "units_search"
                     results["data"] = units
                 else:
                     # List projects in area (using ID)
                     # Note: get_projects currently takes area_name, let's see if we can use ID or name
                     # backend_api.get_projects takes area_name string.
                     projects = backend_api.get_projects(target_area_name) 
                     results["type"] = "projects"
                     results["data"] = projects[:10]
                     results["area_filter"] = target_area_name
             else:
                 results["type"] = "general_qa"
                 results["message"] = "General availability"

        elif inquiry_type == "location_info":
             if target_area_name:
                  results["type"] = "general_qa" 
                  results["context_note"] = f"User asking about location of {target_area_name}"
             else:
                 areas = backend_api.get_all_areas()
                 results["type"] = "areas"
                 results["data"] = areas

        else: # general_qa
            results["type"] = "general_qa"
            results["message"] = "General inquiry"

        state["inquiry_results"] = results
        
    except Exception as e:
        logger.error(f"Node [handle_inquiry]: Error - {e}")
        state["inquiry_results"] = {"error": str(e), "type": "general_qa"}
        
    return state


def validate_names(state: ConversationState) -> ConversationState:
    """Validate and correct area, project, and unit type names against DB.
    
    Uses NameMatcherService for dynamic DB matching with:
    - Arabic normalization
    - Franco Arabic â†’ English conversion (via Cohere)
    - Fuzzy matching with configurable thresholds
    
    Returns:
        Updated state with corrected names or pending_correction for user confirmation.
    """
    from app.services.name_matcher import get_name_matcher_service
    
    matcher = get_name_matcher_service()
    reqs = state.get("extracted_requirements", {})
    pending_correction = None
    
    # Validate Area
    if reqs.get("area") and not reqs.get("area_id"):
        result = matcher.match_area(reqs["area"])
        if result.matched:
            reqs["area"] = result.value
            reqs["area_id"] = result.id
            logger.info(f"Node [validate_names]: Area matched: {result.value}")
        else:
            pending_correction = {
                "field": "area",
                "original": reqs["area"],
                "suggested": result.value,
                "alternatives": result.alternatives,
                "confidence": result.confidence
            }
    
    # Validate Project (only if area resolved)
    if not pending_correction and reqs.get("project") and not reqs.get("project_id"):
        result = matcher.match_project(reqs["project"], area_id=reqs.get("area_id"))
        if result.matched:
            reqs["project"] = result.value
            reqs["project_id"] = result.id
            logger.info(f"Node [validate_names]: Project matched: {result.value}")
        else:
            pending_correction = {
                "field": "project",
                "original": reqs["project"],
                "suggested": result.value,
                "alternatives": result.alternatives,
                "confidence": result.confidence,
                "area_filtered": result.area_filtered
            }
    
    # Validate Unit Type
    if not pending_correction and reqs.get("unit_type") and not reqs.get("unit_type_validated"):
        result = matcher.match_unit_type(reqs["unit_type"])
        if result.matched:
            reqs["unit_type"] = result.value
            reqs["unit_type_validated"] = True
            logger.info(f"Node [validate_names]: Unit type matched: {result.value}")
        else:
            pending_correction = {
                "field": "unit_type",
                "original": reqs["unit_type"],
                "suggested": result.value,
                "alternatives": result.alternatives
            }
    
    state["extracted_requirements"] = reqs
    state["pending_correction"] = pending_correction
    state["names_validated"] = pending_correction is None
    
    return state


def generate_correction_prompt(state: ConversationState) -> ConversationState:
    """Generate Arabic prompt for name correction confirmation.
    
    Shows LLM-converted Franco names and lists projects filtered by area.
    """
    from app.services.name_matcher import get_name_matcher_service
    
    pending = state.get("pending_correction", {})
    if not pending:
        return state
    
    reqs = state.get("extracted_requirements", {})
    matcher = get_name_matcher_service()
    
    field = pending.get("field")
    suggested = pending.get("suggested", "")
    alternatives = pending.get("alternatives", [])
    
    if field == "area":
        alts_list = "\n".join([f"â€¢ {a}" for a in alternatives[:5]])
        state["clarification_question"] = f"""Ø­Ø¶Ø±ØªÙƒ ØªÙ‚ØµØ¯ Ù…Ù†Ø·Ù‚Ø© **{suggested}** ØµØ­ØŸ

Ù„Ùˆ ØªÙ‚ØµØ¯ Ù…Ù†Ø·Ù‚Ø© ØªØ§Ù†ÙŠØ©ØŒ Ù…Ù…ÙƒÙ† ØªØ®ØªØ§Ø±:
{alts_list}"""
    
    elif field == "project":
        area_id = reqs.get("area_id")
        if area_id:
            area_projects = matcher.get_projects_for_area(area_id)
            project_names = [p.get('name', '') for p in area_projects[:10]]
            area_name = reqs.get("area", "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©")
            projects_list = "\n".join([f"â€¢ {p}" for p in project_names if p])
            state["clarification_question"] = f"""Ø­Ø¶Ø±ØªÙƒ ØªÙ‚ØµØ¯ Ù…Ø´Ø±ÙˆØ¹ **{suggested}** ØµØ­ØŸ

Ù…Ø´Ø§Ø±ÙŠØ¹ {area_name}:
{projects_list}

Ù…Ù…ÙƒÙ† ØªØ®ØªØ§Ø± Ø§Ù„Ø§Ø³Ù… Ø¨Ø§Ù„Ø¸Ø¨Ø· âœ¨"""
        else:
            alts_list = "\n".join([f"â€¢ {a}" for a in alternatives[:5]])
            state["clarification_question"] = f"""Ø­Ø¶Ø±ØªÙƒ ØªÙ‚ØµØ¯ Ù…Ø´Ø±ÙˆØ¹ **{suggested}** ØµØ­ØŸ

Ù…Ø´Ø§Ø±ÙŠØ¹ Ù…Ø´Ø§Ø¨Ù‡Ø©:
{alts_list}"""
    
    elif field == "unit_type":
        alts_list = "\n".join([f"â€¢ {a}" for a in alternatives])
        state["clarification_question"] = f"""Ø­Ø¶Ø±ØªÙƒ ØªÙ‚ØµØ¯ **{suggested}** ØµØ­ØŸ

Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØ§Ø­Ø©:
{alts_list}"""
    
    state["awaiting_name_correction"] = True
    return state
