"""
LangGraph node definitions for Broker Chatbot workflow.
Each node represents a step in the conversation processing pipeline.
"""

from typing import Dict, Any
from datetime import datetime
import json

from app.graph.state import BrokerConversationState, ClientAnalysis, StrategyRecommendation
from app.core.llm import get_llm_service
from app.core.logging_config import get_logger
from app.services.backend_api import get_backend_api_service

logger = get_logger(__name__)


def receive_message(state: BrokerConversationState) -> Dict[str, Any]:
    """Entry point - receives and validates the broker's message.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with timestamp and validation.
    """
    logger.info(f"Receiving message from broker {state.get('broker_id')} for request {state.get('request_id')}")
    
    # Validate required fields
    if not state.get('broker_id'):
        return {
            "error": "broker_id is required",
            "timestamp": datetime.now().isoformat()
        }
    
    if not state.get('request_id'):
        return {
            "error": "request_id is required",
            "timestamp": datetime.now().isoformat()
        }
    
    if not state.get('broker_message'):
        return {
            "error": "broker_message is required",
            "timestamp": datetime.now().isoformat()
        }
    
    return {
        "timestamp": datetime.now().isoformat(),
        "error": None
    }


def load_request_context(state: BrokerConversationState) -> Dict[str, Any]:
    """Load request details and conversation history from backend.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with request data and conversations.
    """
    if state.get('error'):
        return {}
    
    broker_id = state.get('broker_id')
    request_id = state.get('request_id')
    
    logger.info(f"Loading context for request {request_id}")
    
    backend_api = get_backend_api_service()
    
    # Get request with conversations (includes access verification)
    request_data = backend_api.get_request_with_conversations(request_id, broker_id)
    
    if not request_data:
        logger.warning(f"Request {request_id} not found or broker {broker_id} not authorized")
        return {
            "error": f"Ø§Ù„Ø·Ù„Ø¨ Ø±Ù‚Ù… {request_id} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù„ÙŠØ³ Ù„Ø¯ÙŠÙƒ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡",
            "access_verified": False
        }
    
    # Extract conversations
    conversations = request_data.get('conversations', [])
    
    # Filter to only customer and AI messages (not broker messages)
    client_conversation = [
        conv for conv in conversations 
        if conv.get('actor_type') in ('customer', 'ai')
    ]
    
    # Format client messages as text for analysis
    client_messages_text = _format_conversations_for_analysis(client_conversation)
    
    logger.info(f"Loaded {len(client_conversation)} client messages for analysis")
    
    return {
        "request_data": {
            "request_id": request_data.get('requestId'),
            "customer_id": request_data.get('customerId'),
            "customer_name": request_data.get('customer', {}).get('name'),
            "customer_phone": request_data.get('customer', {}).get('phone'),
            "area_id": request_data.get('areaId'),
            "area_name": request_data.get('area', {}).get('name'),
            "unit_type": request_data.get('unitType'),
            "budget_min": request_data.get('budgetMin'),
            "budget_max": request_data.get('budgetMax'),
            "size_min": request_data.get('sizeMin'),
            "size_max": request_data.get('sizeMax'),
            "bedrooms": request_data.get('bedrooms'),
            "status": request_data.get('status'),
            "created_at": str(request_data.get('createdAt', '')),
            "assigned_broker_id": request_data.get('assignedBrokerId')
        },
        "client_conversation": client_conversation,
        "client_messages_text": client_messages_text,
        "access_verified": True
    }


def _format_conversations_for_analysis(conversations: list) -> str:
    """Format conversation messages for LLM analysis.
    
    Args:
        conversations: List of conversation messages.
        
    Returns:
        Formatted string of conversations.
    """
    if not conversations:
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø³Ø§Ø¨Ù‚Ø©"
    
    formatted = []
    for conv in conversations:
        actor = "Ø§Ù„Ø¹Ù…ÙŠÙ„" if conv.get('actor_type') == 'customer' else "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¢Ù„ÙŠ"
        message = conv.get('message', '')
        formatted.append(f"{actor}: {message}")
    
    return "\n".join(formatted)


def analyze_client_personality(state: BrokerConversationState) -> Dict[str, Any]:
    """Analyze client personality from conversation history.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with client analysis.
    """
    if state.get('error'):
        return {}
    
    client_messages = state.get('client_messages_text', '')
    request_data = state.get('request_data', {})
    
    if not client_messages or client_messages == "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø³Ø§Ø¨Ù‚Ø©":
        logger.info("No client conversations to analyze")
        return {
            "client_analysis": {
                "personality_type": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "communication_style": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "decision_speed": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "budget_realism": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "seriousness_level": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "risk_level": "Ù…Ù†Ø®ÙØ¶",
                "risk_indicators": [],
                "summary": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„"
            },
            "analysis_complete": False
        }
    
    logger.info("Analyzing client personality...")
    
    llm_service = get_llm_service()
    
    # Build analysis prompt
    analysis_prompt = """Ø­Ù„Ù„ Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ù…Ø­Ø§Ø¯Ø«Ø§ØªÙ‡:

**Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„:**
{conversations}

**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨:**
- Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {area}
- Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø©: {unit_type}
- Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: {budget_min} - {budget_max} Ø¬Ù†ÙŠÙ‡
- Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {size_min} Ù…ØªØ±

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙŠØ´Ù…Ù„:
1. Ù†ÙˆØ¹ Ø§Ù„Ø´Ø®ØµÙŠØ© (Ø­Ø³Ø§Ø³ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© / Ù…Ø³ØªÙƒØ´Ù / Ø¬Ø§Ø¯ / Ù…ØªØ±Ø¯Ø¯ / Ù…ÙØ§ÙˆØ¶)
2. Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙˆØ§ØµÙ„ (Ø±Ø³Ù…ÙŠ / ÙˆØ¯ÙŠ / Ù…Ø¨Ø§Ø´Ø±)
3. Ø³Ø±Ø¹Ø© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± (Ø¹Ø§Ø¬Ù„ / Ù…ØªÙˆØ³Ø· / Ø¨Ø·ÙŠØ¡)
4. ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© (ÙˆØ§Ù‚Ø¹ÙŠ / Ù…ØªÙØ§Ø¦Ù„ / ØºÙŠØ± ÙˆØ§Ù‚Ø¹ÙŠ)
5. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ© (Ø¹Ø§Ù„ÙŠ / Ù…ØªÙˆØ³Ø· / Ù…Ù†Ø®ÙØ¶)
6. Ù…Ù„Ø®Øµ Ù‚ØµÙŠØ± Ù„Ù„Ø¹Ù…ÙŠÙ„

Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± ÙˆÙ…Ø®ØªØµØ±.""".format(
        conversations=client_messages,
        area=request_data.get('area_name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        unit_type=request_data.get('unit_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        budget_min=request_data.get('budget_min', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        budget_max=request_data.get('budget_max', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        size_min=request_data.get('size_min', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
    )
    
    try:
        analysis_response = llm_service.generate_response(analysis_prompt)
        
        # Parse the response into structured analysis
        client_analysis = _parse_personality_analysis(analysis_response)
        
        logger.info(f"Client analysis complete: {client_analysis.get('personality_type')}")
        
        return {
            "client_analysis": client_analysis,
            "analysis_complete": True
        }
        
    except Exception as e:
        logger.error(f"Error analyzing client personality: {e}")
        return {
            "client_analysis": {
                "summary": "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„"
            },
            "analysis_complete": False,
            "error": str(e)
        }


def _parse_personality_analysis(response: str) -> ClientAnalysis:
    """Parse LLM response into structured ClientAnalysis.
    
    Args:
        response: LLM response text.
        
    Returns:
        Structured ClientAnalysis dict.
    """
    # Default values
    analysis: ClientAnalysis = {
        "personality_type": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
        "communication_style": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
        "decision_speed": "Ù…ØªÙˆØ³Ø·",
        "budget_realism": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
        "seriousness_level": "Ù…ØªÙˆØ³Ø·",
        "risk_level": "Ù…ØªÙˆØ³Ø·",
        "risk_indicators": [],
        "summary": response
    }
    
    # Try to extract structured info from response
    response_lower = response.lower()
    
    # Personality type detection
    if any(word in response for word in ['Ø­Ø³Ø§Ø³ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©', 'Ø­Ø³Ø§Ø³ Ù„Ù„Ø³Ø¹Ø±', 'budget-sensitive']):
        analysis['personality_type'] = 'Ø­Ø³Ø§Ø³ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©'
    elif any(word in response for word in ['Ù…Ø³ØªÙƒØ´Ù', 'Ø§Ø³ØªÙƒØ´Ø§Ù', 'exploratory']):
        analysis['personality_type'] = 'Ù…Ø³ØªÙƒØ´Ù'
    elif any(word in response for word in ['Ø¬Ø§Ø¯', 'Ø¬Ø¯ÙŠ', 'serious']):
        analysis['personality_type'] = 'Ø¬Ø§Ø¯'
    elif any(word in response for word in ['Ù…ØªØ±Ø¯Ø¯', 'hesitant']):
        analysis['personality_type'] = 'Ù…ØªØ±Ø¯Ø¯'
    elif any(word in response for word in ['Ù…ÙØ§ÙˆØ¶', 'negotiator']):
        analysis['personality_type'] = 'Ù…ÙØ§ÙˆØ¶'
    
    # Seriousness level
    if any(word in response for word in ['Ø¬Ø¯ÙŠØ© Ø¹Ø§Ù„ÙŠØ©', 'Ø¹Ø§Ù„ÙŠ', 'high']):
        analysis['seriousness_level'] = 'Ø¹Ø§Ù„ÙŠ'
    elif any(word in response for word in ['Ù…Ù†Ø®ÙØ¶', 'low', 'Ø¶Ø¹ÙŠÙ']):
        analysis['seriousness_level'] = 'Ù…Ù†Ø®ÙØ¶'
    
    # Decision speed
    if any(word in response for word in ['Ø¹Ø§Ø¬Ù„', 'Ø³Ø±ÙŠØ¹', 'urgent']):
        analysis['decision_speed'] = 'Ø¹Ø§Ø¬Ù„'
    elif any(word in response for word in ['Ø¨Ø·ÙŠØ¡', 'slow']):
        analysis['decision_speed'] = 'Ø¨Ø·ÙŠØ¡'
    
    return analysis


def assess_request_risk(state: BrokerConversationState) -> Dict[str, Any]:
    """Assess risk level of the request.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with risk assessment.
    """
    if state.get('error'):
        return {}
    
    client_analysis = state.get('client_analysis', {})
    client_messages = state.get('client_messages_text', '')
    
    risk_indicators = []
    risk_level = 'Ù…Ù†Ø®ÙØ¶'
    
    # Check for risk indicators
    if 'Ù…ØªØ±Ø¯Ø¯' in client_analysis.get('personality_type', ''):
        risk_indicators.append('Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…ØªØ±Ø¯Ø¯ ÙÙŠ Ù‚Ø±Ø§Ø±Ø§ØªÙ‡')
        risk_level = 'Ù…ØªÙˆØ³Ø·'
    
    if client_analysis.get('budget_realism') == 'ØºÙŠØ± ÙˆØ§Ù‚Ø¹ÙŠ':
        risk_indicators.append('ØªÙˆÙ‚Ø¹Ø§Øª Ù…ÙŠØ²Ø§Ù†ÙŠØ© ØºÙŠØ± ÙˆØ§Ù‚Ø¹ÙŠØ©')
        risk_level = 'Ø¹Ø§Ù„ÙŠ'
    
    if client_analysis.get('seriousness_level') == 'Ù…Ù†Ø®ÙØ¶':
        risk_indicators.append('Ù…Ø³ØªÙˆÙ‰ Ø¬Ø¯ÙŠØ© Ù…Ù†Ø®ÙØ¶')
        risk_level = 'Ø¹Ø§Ù„ÙŠ'
    
    # Check conversation patterns
    if client_messages:
        # Multiple mentions of budget changes
        budget_mentions = client_messages.lower().count('Ù…ÙŠØ²Ø§Ù†ÙŠØ©') + client_messages.lower().count('Ø³Ø¹Ø±')
        if budget_mentions > 3:
            risk_indicators.append('ØªØºÙŠÙŠØ±Ø§Øª Ù…ØªÙƒØ±Ø±Ø© ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©')
            risk_level = 'Ù…ØªÙˆØ³Ø·' if risk_level == 'Ù…Ù†Ø®ÙØ¶' else risk_level
    
    logger.info(f"Risk assessment: {risk_level} with {len(risk_indicators)} indicators")
    
    # Update analysis with risk info
    updated_analysis = {**client_analysis}
    updated_analysis['risk_level'] = risk_level
    updated_analysis['risk_indicators'] = risk_indicators
    
    return {
        "client_analysis": updated_analysis
    }


def generate_strategy(state: BrokerConversationState) -> Dict[str, Any]:
    """Generate broker strategy recommendations.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with strategy recommendations.
    """
    if state.get('error'):
        return {}
    
    client_analysis = state.get('client_analysis', {})
    request_data = state.get('request_data', {})
    client_messages = state.get('client_messages_text', '')
    
    logger.info("Generating broker strategy...")
    
    llm_service = get_llm_service()
    
    strategy_prompt = """Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ù‚Ø¯Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ù„ÙˆØ³ÙŠØ·:

**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„:**
- Ù†ÙˆØ¹ Ø§Ù„Ø´Ø®ØµÙŠØ©: {personality}
- Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ©: {seriousness}
- Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {risk}
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: {risk_indicators}

**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨:**
- Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {area}
- Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: {budget_min} - {budget_max}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
1. Ø§Ù„Ù†Ø¨Ø±Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ØªÙˆØ§ØµÙ„ (ÙˆØ¯ÙŠØ© / Ù…Ù‡Ù†ÙŠØ© / Ù…Ø·Ù…Ø¦Ù†Ø©)
2. Ø¬Ù…Ù„Ø© Ø§ÙØªØªØ§Ø­ÙŠØ© Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¹Ù…ÙŠÙ„
3. Ù†Ù‚Ø§Ø· Ù…Ù‡Ù…Ø© ÙŠØ¬Ø¨ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„ÙŠÙ‡Ø§ (3 Ù†Ù‚Ø§Ø·)
4. ØªØ­Ø°ÙŠØ±Ø§Øª ÙŠØ¬Ø¨ Ù…Ø±Ø§Ø¹Ø§ØªÙ‡Ø§
5. Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙØ§ÙˆØ¶

Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªØµØ± ÙˆØ¹Ù…Ù„ÙŠ.""".format(
        personality=client_analysis.get('personality_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        seriousness=client_analysis.get('seriousness_level', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        risk=client_analysis.get('risk_level', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        risk_indicators=', '.join(client_analysis.get('risk_indicators', [])) or 'Ù„Ø§ ØªÙˆØ¬Ø¯',
        area=request_data.get('area_name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        budget_min=request_data.get('budget_min', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        budget_max=request_data.get('budget_max', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
    )
    
    try:
        strategy_response = llm_service.generate_response(strategy_prompt)
        
        strategy: StrategyRecommendation = {
            "summary": strategy_response,
            "communication_tone": _extract_tone(strategy_response),
            "key_points": [],
            "warnings": client_analysis.get('risk_indicators', []),
            "negotiation_tips": []
        }
        
        logger.info("Strategy generation complete")
        
        return {
            "strategy": strategy
        }
        
    except Exception as e:
        logger.error(f"Error generating strategy: {e}")
        return {
            "strategy": {
                "summary": "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"
            }
        }


def _extract_tone(response: str) -> str:
    """Extract recommended tone from LLM response."""
    if any(word in response for word in ['ÙˆØ¯ÙŠØ©', 'ÙˆØ¯ÙŠ', 'friendly']):
        return 'ÙˆØ¯ÙŠØ©'
    elif any(word in response for word in ['Ù…Ø·Ù…Ø¦Ù†Ø©', 'reassuring']):
        return 'Ù…Ø·Ù…Ø¦Ù†Ø©'
    elif any(word in response for word in ['Ø­Ø§Ø²Ù…', 'assertive']):
        return 'Ø­Ø§Ø²Ù…Ø©'
    return 'Ù…Ù‡Ù†ÙŠØ©'


def handle_broker_question(state: BrokerConversationState) -> Dict[str, Any]:
    """Handle specific question from broker.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with answer to broker's question.
    """
    if state.get('error'):
        return {}
    
    broker_message = state.get('broker_message', '')
    client_analysis = state.get('client_analysis', {})
    strategy = state.get('strategy', {})
    client_messages = state.get('client_messages_text', '')
    request_data = state.get('request_data', {})
    
    logger.info(f"Handling broker question: {broker_message[:50]}...")
    
    llm_service = get_llm_service()
    
    # Build context for answering the question
    context = f"""
**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„:**
{client_analysis.get('summary', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„')}

**Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**
{strategy.get('summary', 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©')}

**Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„:**
{client_messages}

**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨:**
- Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {request_data.get('area_name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: {request_data.get('budget_min', '?')} - {request_data.get('budget_max', '?')}
- Ù†ÙˆØ¹ Ø§Ù„ÙˆØ­Ø¯Ø©: {request_data.get('unit_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
"""
    
    try:
        response = llm_service.generate_response(
            user_message=broker_message,
            context=context
        )
        
        return {
            "response": response
        }
        
    except Exception as e:
        logger.error(f"Error handling broker question: {e}")
        return {
            "response": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
        }


def generate_response(state: BrokerConversationState) -> Dict[str, Any]:
    """Generate final response for the broker.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with final response.
    """
    # If there's already a response (from handle_broker_question), use it
    if state.get('response'):
        return {}
    
    # If there's an error, return error message
    if state.get('error'):
        return {
            "response": f"âŒ {state.get('error')}"
        }
    
    # Build comprehensive response from analysis and strategy
    client_analysis = state.get('client_analysis', {})
    strategy = state.get('strategy', {})
    request_data = state.get('request_data', {})
    
    # Format response
    response_parts = []
    
    # Header
    response_parts.append(f"ğŸ“Š **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ Ø±Ù‚Ù… {request_data.get('request_id', '?')}**\n")
    
    # Client Analysis Section
    response_parts.append("ğŸ§‘ **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„:**")
    response_parts.append(f"â€¢ Ù†ÙˆØ¹ Ø§Ù„Ø´Ø®ØµÙŠØ©: {client_analysis.get('personality_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
    response_parts.append(f"â€¢ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ©: {client_analysis.get('seriousness_level', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
    response_parts.append(f"â€¢ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {client_analysis.get('risk_level', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
    
    if client_analysis.get('risk_indicators'):
        response_parts.append(f"â€¢ ØªØ­Ø°ÙŠØ±Ø§Øª: {', '.join(client_analysis['risk_indicators'])}")
    
    response_parts.append("")
    
    # Strategy Section
    response_parts.append("ğŸ’¡ **Ø§Ù„ØªÙˆØµÙŠØ§Øª:**")
    response_parts.append(f"â€¢ Ù†Ø¨Ø±Ø© Ø§Ù„ØªÙˆØ§ØµÙ„: {strategy.get('communication_tone', 'Ù…Ù‡Ù†ÙŠØ©')}")
    
    if strategy.get('summary'):
        response_parts.append(f"\n{strategy['summary']}")
    
    final_response = "\n".join(response_parts)
    
    logger.info("Generated final response for broker")
    
    return {
        "response": final_response
    }


def detect_question_type(state: BrokerConversationState) -> Dict[str, Any]:
    """Detect if broker message is a question and its type.
    
    Args:
        state: Current conversation state.
        
    Returns:
        Updated state with question detection results.
    """
    broker_message = state.get('broker_message', '').lower()
    
    # Check if it's a question
    question_words = ['ØŸ', '?', 'Ù‡Ù„', 'Ù…Ø§', 'ÙƒÙŠÙ', 'Ù„Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ø§Ø²Ø§ÙŠ', 'Ù„ÙŠÙ‡', 'Ø§ÙŠÙ‡']
    has_question = any(word in broker_message for word in question_words)
    
    # Determine question type
    question_type = None
    if has_question:
        if any(word in broker_message for word in ['Ø¬Ø§Ø¯', 'Ø¬Ø¯ÙŠ', 'Ø³ÙŠØ±ÙŠØ§Ø³', 'serious']):
            question_type = 'seriousness'
        elif any(word in broker_message for word in ['Ø®Ø·Ø±', 'Ù…Ø®Ø§Ø·Ø±', 'risk']):
            question_type = 'risk'
        elif any(word in broker_message for word in ['Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'Ø§ØªØ¹Ø§Ù…Ù„', 'ØªØ¹Ø§Ù…Ù„', 'strategy']):
            question_type = 'strategy'
        elif any(word in broker_message for word in ['Ø´Ø®ØµÙŠØ©', 'personality']):
            question_type = 'personality'
        else:
            question_type = 'general'
    
    return {
        "has_question": has_question,
        "question_type": question_type,
        "is_first_message": not state.get('session_history')
    }
